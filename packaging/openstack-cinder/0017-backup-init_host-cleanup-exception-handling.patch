From 606c3597f90164a82ed7f0daec195b9c2412b34b Mon Sep 17 00:00:00 2001
From: Tom Barron <tpb@dyncloud.net>
Date: Wed, 26 Aug 2015 16:07:00 -0400
Subject: [PATCH 17/17] backup init_host cleanup exception handling

Current cleanup of leftover backups, volumes, and temporary
volumes and snapshots is not resilient in the face of exceptions
such as failures in detach operations.

This commit adds appropriate try/except logic to this section
of code, thereby ensuring that the backup service can start even
if exceptions are encountered when attempting to cleanup detritus
from earlier failed backup operations.

Change-Id: Ie8d2107ebd4d86dfe5664c35687e8cbe58cfad9d
Closes-bug: 1485295
(cherry picked from commit bda6da1f8df44a64e8b320ebd8e2211197b6afeb)

Conflicts:
      cinder/backup/manager.py
      cinder/tests/test_backup.py

(cherry picked from commit d65c03ccfa18be466987c7e613dcbc5e9b32b047)

Conflicts:
      cinder/backup/manager.py
---
 cinder/backup/manager.py    | 199 ++++++++++++++++++++++++++------------------
 cinder/tests/test_backup.py | 197 ++++++++++++++++++++++++++++++++++++-------
 2 files changed, 283 insertions(+), 113 deletions(-)

diff --git a/cinder/backup/manager.py b/cinder/backup/manager.py
index 4314a57..8bcadc8 100644
--- a/cinder/backup/manager.py
+++ b/cinder/backup/manager.py
@@ -192,108 +192,141 @@ class BackupManager(manager.SchedulerDependentManager):
         for mgr in self.volume_managers.itervalues():
             self._init_volume_driver(ctxt, mgr.driver)
 
+        try:
+            self._cleanup_incomplete_backup_operations(ctxt)
+        except Exception:
+            # Don't block startup of the backup service.
+            LOG.exception(_("Problem cleaning incomplete backup "
+                              "operations."))
+
+    def _cleanup_incomplete_backup_operations(self, ctxt):
         LOG.info(_("Cleaning up incomplete backup operations."))
         volumes = self.db.volume_get_all_by_host(ctxt, self.host)
+
         for volume in volumes:
-            volume_host = volume_utils.extract_host(volume['host'], 'backend')
-            backend = self._get_volume_backend(host=volume_host)
-            mgr = self._get_manager(backend)
-            if volume['status'] == 'backing-up':
-                self._detach_volume(ctxt, mgr, volume)
-                LOG.info(_('Resetting volume %(vol_id)s to previous '
-                             'status %(status)s (was backing-up).'),
-                         {'vol_id': volume['id'],
-                          'status': volume['previous_status']})
-                self.db.volume_update(ctxt, volume['id'],
-                                      {'status': volume['previous_status']})
-            elif volume['status'] == 'restoring-backup':
-                self._detach_volume(ctxt, mgr, volume)
-                LOG.info(_('setting volume %s to error_restoring '
-                             '(was restoring-backup).'), volume['id'])
-                self.db.volume_update(ctxt, volume['id'],
-                                      {'status': 'error_restoring'})
+            try:
+                self._cleanup_one_volume(ctxt, volume)
+            except Exception:
+                LOG.exception(_("Problem cleaning up volume %(vol)s."),
+                              {'vol': volume['id']})
 
         # TODO(smulcahy) implement full resume of backup and restore
         # operations on restart (rather than simply resetting)
         backups = self.db.backup_get_all_by_host(ctxt, self.host)
         for backup in backups:
-            if backup['status'] == 'creating':
-                LOG.info(_('Resetting backup %s to error (was creating).')
-                         % backup['id'])
-                err = 'incomplete backup reset on manager restart'
-                backup['status'] = 'error'
-                backup['fail_reason'] = err
-                self.db.backup_update(ctxt, backup['id'], {'status': 'error',
-                                                           'fail_reason': err})
-            if backup['status'] == 'restoring':
-                LOG.info(_('Resetting backup %s to available (was restoring).')
-                         % backup['id'])
-                backup['status'] = 'available'
-                self.db.backup_update(ctxt, backup['id'],
-                                      {'status': 'available'})
-            if backup['status'] == 'deleting':
-                LOG.info(_('Resuming delete on backup: %s.') % backup['id'])
-                self.delete_backup(ctxt, backup['id'])
-
-        self._cleanup_temp_volumes_snapshots(backups)
+            try:
+                self._cleanup_one_backup(ctxt, backup)
+            except Exception:
+                LOG.exception(_("Problem cleaning up backup %(bkup)s."),
+                              {'bkup': backup['id']})
+            try:
+                self._cleanup_temp_volumes_snapshots_for_one_backup(ctxt,
+                                                                    backup)
+            except Exception:
+                LOG.exception(_("Problem cleaning temp volumes and "
+                                  "snapshots for backup %(bkup)s."),
+                              {'bkup': backup['id']})
+
+    def _cleanup_one_volume(self, ctxt, volume):
+        volume_host = volume_utils.extract_host(volume['host'], 'backend')
+        backend = self._get_volume_backend(host=volume_host)
+        mgr = self._get_manager(backend)
+        if volume['status'] == 'backing-up':
+            self._detach_volume(ctxt, mgr, volume)
+            LOG.info(_('Resetting volume %(vol_id)s to previous '
+                         'status %(status)s (was backing-up).'),
+                     {'vol_id': volume['id'],
+                      'status': volume['previous_status']})
+            self.db.volume_update(ctxt, volume['id'],
+                                  {'status': volume['previous_status']})
+        elif volume['status'] == 'restoring-backup':
+            self._detach_volume(ctxt, mgr, volume)
+            LOG.info(_('setting volume %s to error_restoring '
+                         '(was restoring-backup).'), volume['id'])
+            self.db.volume_update(ctxt, volume['id'],
+                                  {'status': 'error_restoring'})
+
+    def _cleanup_one_backup(self, ctxt, backup):
+        if backup['status'] == 'creating':
+            LOG.info(_('Resetting backup %s to error (was creating).'),
+                     backup['id'])
+            err = 'incomplete backup reset on manager restart'
+            backup['status'] = 'error'
+            backup['fail_reason'] = err
+            self.db.backup_update(ctxt, backup['id'], {'status': 'error',
+                                                       'fail_reason': err})
+        if backup['status'] == 'restoring':
+            LOG.info(_('Resetting backup %s to '
+                         'available (was restoring).'),
+                     backup['id'])
+            backup['status'] = 'available'
+            self.db.backup_update(ctxt, backup['id'],
+                                  {'status': 'available'})
+        if backup['status'] == 'deleting':
+            LOG.info(_('Resuming delete on backup: %s.'), backup['id'])
+            self.delete_backup(ctxt, backup['id'])
 
     def _detach_volume(self, ctxt, mgr, volume):
         if (volume['attach_status'] == 'attached' and
                 volume['attached_host'] == self.host and
                 volume['instance_uuid'] == None):
-            mgr.detach_volume(ctxt, volume['id'])
+            try:
+                mgr.detach_volume(ctxt, volume['id'])
+            except Exception:
+                LOG.exception(_("Detach %(vol)s failed."),
+                              {'vol': volume['id']})
 
-    def _cleanup_temp_volumes_snapshots(self, backups):
+    def _cleanup_temp_volumes_snapshots_for_one_backup(self, ctxt, backup):
         # NOTE(xyang): If the service crashes or gets restarted during the
         # backup operation, there could be temporary volumes or snapshots
         # that are not deleted. Make sure any temporary volumes or snapshots
         # create by the backup job are deleted when service is started.
-        ctxt = context.get_admin_context()
-        for backup in backups:
+        try:
+            volume = self.db.volume_get(ctxt, backup.volume_id)
+            volume_host = volume_utils.extract_host(volume['host'],
+                                                    'backend')
+            backend = self._get_volume_backend(host=volume_host)
+            mgr = self._get_manager(backend)
+        except (KeyError, exception.VolumeNotFound):
+            LOG.debug("Could not find a volume to clean up for "
+                      "backup %s.", backup.id)
+            return
+
+        if backup['temp_volume_id'] and backup['status'] == 'error':
+            try:
+                temp_volume = self.db.volume_get(ctxt,
+                                                 backup.temp_volume_id)
+                # The temp volume should be deleted directly thru the
+                # the volume driver, not thru the volume manager.
+                mgr.driver.delete_volume(temp_volume)
+                self.db.volume_destroy(ctxt, temp_volume['id'])
+            except exception.VolumeNotFound:
+                LOG.debug("Could not find temp volume %(vol)s to clean up "
+                          "for backup %(backup)s.",
+                          {'vol': backup.temp_volume_id,
+                           'backup': backup.id})
+            backup['temp_volume_id'] = None
+            self.db.backup_update(ctxt, backup['id'],
+                                  {'temp_volume_id': None})
+
+        if backup['temp_snapshot_id'] and backup['status'] == 'error':
             try:
-                volume = self.db.volume_get(ctxt, backup['volume_id'])
-                volume_host = volume_utils.extract_host(volume['host'],
-                                                        'backend')
-                backend = self._get_volume_backend(host=volume_host)
-                mgr = self._get_manager(backend)
-            except (KeyError, exception.VolumeNotFound):
-                LOG.debug("Could not find a volume to clean up for "
-                          "backup %s.", backup.id)
-                continue
-            if backup['temp_volume_id'] and backup['status'] == 'error':
-                try:
-                    temp_volume = self.db.volume_get(ctxt,
-                                                     backup['temp_volume_id'])
-                    # The temp volume should be deleted directly thru the
-                    # the volume driver, not thru the volume manager.
-                    mgr.driver.delete_volume(temp_volume)
-                    self.db.volume_destroy(ctxt, temp_volume['id'])
-                except exception.VolumeNotFound:
-                    LOG.debug("Could not find temp volume %(vol)s to clean up "
-                              "for backup %(backup)s.",
-                              {'vol': backup['temp_volume_id'],
-                               'backup': backup['id']})
-                backup['temp_volume_id'] = None
-                self.db.backup_update(ctxt, backup['id'],
-                                      {'temp_volume_id': None})
-            if backup['temp_snapshot_id'] and backup['status'] == 'error':
-                try:
-                    temp_snapshot = self.db.snapshot_get(
-                            ctxt, backup['temp_snapshot_id'])
-                    # The temp snapshot should be deleted directly thru the
-                    # volume driver, not thru the volume manager.
-                    mgr.driver.delete_snapshot(temp_snapshot)
-                    self.db.volume_glance_metadata_delete_by_snapshot(
-                            ctxt, temp_snapshot['id'])
-                    self.db.snapshot_destroy(ctxt, temp_snapshot['id'])
-                except exception.SnapshotNotFound:
-                    LOG.debug("Could not find temp snapshot %(snap)s to clean "
-                              "up for backup %(backup)s.",
-                              {'snap': backup['temp_snapshot_id'],
-                               'backup': backup['id']})
-                backup['temp_snapshot_id'] = None
-                self.db.backup_update(ctxt, backup['id'],
-                                      {'temp_snapshot_id': None})
+                temp_snapshot = self.db.snapshot_get(
+                        ctxt, backup['temp_snapshot_id'])
+                # The temp snapshot should be deleted directly thru the
+                # volume driver, not thru the volume manager.
+                mgr.driver.delete_snapshot(temp_snapshot)
+                self.db.volume_glance_metadata_delete_by_snapshot(
+                        ctxt, temp_snapshot['id'])
+                self.db.snapshot_destroy(ctxt, temp_snapshot['id'])
+            except exception.SnapshotNotFound:
+                LOG.debug("Could not find temp snapshot %(snap)s to clean "
+                          "up for backup %(backup)s.",
+                          {'snap': backup['temp_snapshot_id'],
+                           'backup': backup['id']})
+            backup['temp_snapshot_id'] = None
+            self.db.backup_update(ctxt, backup['id'],
+                                  {'temp_snapshot_id': None})
 
     def create_backup(self, context, backup_id):
         """Create volume backups using configured backup service."""
diff --git a/cinder/tests/test_backup.py b/cinder/tests/test_backup.py
index 914bc52..1e90044 100644
--- a/cinder/tests/test_backup.py
+++ b/cinder/tests/test_backup.py
@@ -210,6 +210,7 @@ class BackupTestCase(BaseBackupTest):
                                      temp_snapshot_id=temp_snap_id)
 
         self.backup_mgr.init_host()
+
         vol1 = db.volume_get(self.ctxt, vol1_id)
         self.assertEqual(vol1['status'], 'available')
         vol2 = db.volume_get(self.ctxt, vol2_id)
@@ -235,58 +236,194 @@ class BackupTestCase(BaseBackupTest):
         self.assertTrue(mock_delete_volume.called)
         self.assertTrue(mock_delete_snapshot.called)
 
+    @mock.patch.object(manager.BackupManager,
+                       '_cleanup_incomplete_backup_operations')
+    @mock.patch.object(manager.BackupManager, '_init_volume_driver')
+    def test_init_host_handles_exception(
+            self, mock_init_driver, mock_cleanup):
+        """Test that exception in cleanup is handled."""
+
+        mock_cleanup.side_effect = [Exception]
+
+        self.assertIsNone(self.backup_mgr.init_host())
+
+    @mock.patch.object(manager.BackupManager,
+                       '_cleanup_temp_volumes_snapshots_for_one_backup')
+    @mock.patch.object(manager.BackupManager, '_cleanup_one_backup')
+    @mock.patch.object(db, 'backup_get_all_by_host')
+    @mock.patch.object(manager.BackupManager, '_cleanup_one_volume')
+    @mock.patch.object(db, 'volume_get_all_by_host')
+    def test_cleanup_incomplete_backup_operations_with_exceptions(
+            self, mock_volume_get_by_host, mock_volume_cleanup,
+            mock_backup_get_by_host, mock_backup_cleanup,
+            mock_temp_cleanup):
+        """Test cleanup resilience in the face of exceptions."""
+
+        fake_volume_list = [{'id': 'vol1'}, {'id': 'vol2'}]
+        mock_volume_get_by_host.return_value = fake_volume_list
+
+        mock_volume_cleanup.side_effect = [Exception]
+
+        fake_backup_list = [{'id': 'bkup1'}, {'id': 'bkup2'}, {'id': 'bkup3'}]
+        mock_backup_get_by_host.return_value = fake_backup_list
+
+        mock_backup_cleanup.side_effect = [Exception]
+
+        mock_temp_cleanup.side_effect = [Exception]
+
+        self.assertIsNone(
+            self.backup_mgr._cleanup_incomplete_backup_operations(
+                self.ctxt))
+
+        self.assertEqual(len(fake_volume_list), mock_volume_cleanup.call_count)
+        self.assertEqual(len(fake_backup_list), mock_backup_cleanup.call_count)
+        self.assertEqual(len(fake_backup_list), mock_temp_cleanup.call_count)
+
+    @mock.patch.object(manager.BackupManager, '_get_manager')
+    def test_cleanup_one_backing_up_volume(self, mock_get_manager):
+        """Test cleanup_one_volume for volume status 'backing-up'."""
+
+        mock_get_manager.return_value = 'fake_manager'
+
+        volume_id = self._create_volume_db_entry(status='backing-up',
+                                                 previous_status='available')
+        volume = db.volume_get(self.ctxt, volume_id)
+
+        self.backup_mgr._cleanup_one_volume(self.ctxt, volume)
+
+        volume = db.volume_get(self.ctxt, volume_id)
+        self.assertEqual('available', volume['status'])
+
+    @mock.patch.object(manager.BackupManager, '_get_manager')
+    def test_cleanup_one_restoring_backup_volume(self, mock_get_manager):
+        """Test cleanup_one_volume for volume status 'restoring-backup'."""
+
+        mock_get_manager.return_value = 'fake_manager'
+
+        volume_id = self._create_volume_db_entry(status='restoring-backup')
+        volume = db.volume_get(self.ctxt, volume_id)
+
+        self.backup_mgr._cleanup_one_volume(self.ctxt, volume)
+
+        volume = db.volume_get(self.ctxt, volume_id)
+        self.assertEqual('error_restoring', volume['status'])
+
+    def test_cleanup_one_creating_backup(self):
+        """Test cleanup_one_backup for volume status 'creating'."""
+
+        backup_id = self._create_backup_db_entry(status='creating')
+        backup = db.backup_get(self.ctxt, backup_id)
+
+        self.backup_mgr._cleanup_one_backup(self.ctxt, backup)
+
+        self.assertEqual('error', backup['status'])
+
+    def test_cleanup_one_restoring_backup(self):
+        """Test cleanup_one_backup for volume status 'restoring'."""
+
+        backup_id = self._create_backup_db_entry(status='restoring')
+        backup = db.backup_get(self.ctxt, backup_id)
+
+        self.backup_mgr._cleanup_one_backup(self.ctxt, backup)
+
+        self.assertEqual('available', backup['status'])
+
+    def test_cleanup_one_deleting_backup(self):
+        """Test cleanup_one_backup for volume status 'deleting'."""
+
+        backup_id = self._create_backup_db_entry(status='deleting')
+        backup = db.backup_get(self.ctxt, backup_id)
+
+        self.backup_mgr._cleanup_one_backup(self.ctxt, backup)
+
+        self.assertRaises(exception.BackupNotFound,
+                          db.backup_get,
+                          self.ctxt,
+                          backup['id'])
+
+    @mock.patch.object(manager, 'LOG')
+    def test_detach_all_attachments_handles_exceptions(self, mock_log):
+        """Test detach_all_attachments with exceptions."""
+
+        mock_volume_mgr = mock.Mock()
+        mock_detach_volume = mock_volume_mgr.detach_volume
+        mock_detach_volume.side_effect = [Exception]
+
+        fake_volume = {
+            'id': 'fake_volume_id',
+            'attach_status': 'attached',
+            'attached_host': 'testhost',
+            'instance_uuid': None,
+        }
+
+        self.backup_mgr._detach_volume(self.ctxt,
+                                       mock_volume_mgr,
+                                       fake_volume)
+
+        self.assertEqual(1, mock_log.exception.call_count)
+
     @mock.patch.object(db, 'volume_get')
     @ddt.data(KeyError, exception.VolumeNotFound)
-    def test_cleanup_temp_volumes_snapshots_volume_not_found(
+    def test_cleanup_temp_volumes_snapshots_for_one_backup_volume_not_found(
             self, err, mock_volume_get):
         """Ensure we handle missing volume for a backup."""
+
         mock_volume_get.side_effect = [err]
 
-        backup1_id = self._create_backup_db_entry(status='creating')
-        backup1 = db.backup_get(self.ctxt, backup1_id)
-        backups = [backup1]
+        backup_id = self._create_backup_db_entry(status='creating')
+        backup = db.backup_get(self.ctxt, backup_id)
 
-        self.assertIsNone(self.backup_mgr._cleanup_temp_volumes_snapshots(
-            backups))
+        self.assertIsNone(
+            self.backup_mgr._cleanup_temp_volumes_snapshots_for_one_backup(
+                self.ctxt,
+                backup))
 
     @mock.patch.object(lvm.LVMVolumeDriver, 'delete_snapshot')
-    def test_cleanup_temp_snapshot_not_found(self,
-                                             mock_delete_snapshot):
+    def test_cleanup_temp_snapshot_for_one_backup_not_found(
+            self, mock_delete_snapshot):
         """Ensure we handle missing temp snapshot for a backup."""
+
         vol1_id = self._create_volume_db_entry()
         self._create_volume_attach(vol1_id)
         db.volume_update(self.ctxt, vol1_id, {'status': 'backing-up'})
-        backup1_id = self._create_backup_db_entry(status='error',
-                                                  volume_id=vol1_id,
-                                                  temp_snapshot_id='fake')
-        backup1 = db.backup_get(self.ctxt, backup1_id)
-        backups = [backup1]
-        self.assertEqual('fake', backups[0]['temp_snapshot_id'])
-        self.assertIsNone(self.backup_mgr._cleanup_temp_volumes_snapshots(
-            backups))
+        backup_id = self._create_backup_db_entry(status='error',
+                                                 volume_id=vol1_id,
+                                                 temp_snapshot_id='fake')
+        backup = db.backup_get(self.ctxt, backup_id)
+
+        self.assertIsNone(
+            self.backup_mgr._cleanup_temp_volumes_snapshots_for_one_backup(
+                self.ctxt,
+                backup))
+
         self.assertFalse(mock_delete_snapshot.called)
-        self.assertIsNone(backups[0]['temp_snapshot_id'])
-        db.backup_destroy(self.ctxt, backup1_id)
+        self.assertIsNone(backup['temp_snapshot_id'])
+
+        db.backup_destroy(self.ctxt, backup_id)
         db.volume_destroy(self.ctxt, vol1_id)
 
     @mock.patch.object(lvm.LVMVolumeDriver, 'delete_volume')
-    def test_cleanup_temp_volume_not_found(self,
-                                           mock_delete_volume):
+    def test_cleanup_temp_volume_for_one_backup_not_found(
+            self, mock_delete_volume):
         """Ensure we handle missing temp volume for a backup."""
+
         vol1_id = self._create_volume_db_entry()
         self._create_volume_attach(vol1_id)
         db.volume_update(self.ctxt, vol1_id, {'status': 'backing-up'})
-        backup1_id = self._create_backup_db_entry(status='error',
-                                                  volume_id=vol1_id,
-                                                  temp_volume_id='fake')
-        backup1 = db.backup_get(self.ctxt, backup1_id)
-        backups = [backup1]
-        self.assertEqual('fake', backups[0]['temp_volume_id'])
-        self.assertIsNone(self.backup_mgr._cleanup_temp_volumes_snapshots(
-            backups))
+        backup_id = self._create_backup_db_entry(status='error',
+                                                 volume_id=vol1_id,
+                                                 temp_volume_id='fake')
+        backup = db.backup_get(self.ctxt, backup_id)
+
+        self.assertIsNone(
+            self.backup_mgr._cleanup_temp_volumes_snapshots_for_one_backup(
+                self.ctxt,
+                backup))
+
         self.assertFalse(mock_delete_volume.called)
-        self.assertIsNone(backups[0]['temp_volume_id'])
-        db.backup_destroy(self.ctxt, backup1_id)
+        self.assertIsNone(backup['temp_volume_id'])
+
+        db.backup_destroy(self.ctxt, backup_id)
         db.volume_destroy(self.ctxt, vol1_id)
 
     def test_create_backup_with_bad_volume_status(self):
-- 
2.8.1

