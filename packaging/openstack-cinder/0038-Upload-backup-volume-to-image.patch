From 0178f268d79e52c8dd3096cd5b09d88148b32925 Mon Sep 17 00:00:00 2001
From: Xiaojun Liao <xiaojunliao85@gmail.com>
Date: Tue, 18 Jul 2017 16:48:53 +0800
Subject: [PATCH 38/54] Upload backup volume to image

Fixes: Feature #10587

This patch implements creating image from backup of volume, using
ceph backend clone or a local tempfile uploading.

Signed-off-by: Xiaojun Liao <xiaojunliao85@gmail.com>
(cherry picked from commit f01dc3289e079107c699a3200c3efc0207c4fe86)
---
 cinder/api/contrib/backups.py |  43 ++++-
 cinder/api/views/backups.py   |  17 ++
 cinder/backup/api.py          |  54 +++++++
 cinder/backup/drivers/ceph.py | 353 +++++++++++++++++++++++++++++++++++++++++-
 cinder/backup/manager.py      |  86 ++++++++++
 cinder/backup/rpcapi.py       |   6 +
 cinder/exception.py           |   4 +
 cinder/image/image_utils.py   |  16 +-
 8 files changed, 571 insertions(+), 8 deletions(-)

diff --git a/cinder/api/contrib/backups.py b/cinder/api/contrib/backups.py
index be12feb79..46780fdd1 100644
--- a/cinder/api/contrib/backups.py
+++ b/cinder/api/contrib/backups.py
@@ -266,6 +266,45 @@ class BackupsController(wsgi.Controller):
         retval = self._view_builder.summary(req, dict(new_backup.iteritems()))
         return retval
 
+    @wsgi.response(202)
+    def upload(self, req, id, body):
+        """Upload an existing backup to image service."""
+        LOG.debug('Uploading backup %(backup_id)s (%(body)s)',
+                  {'backup_id': id, 'body': body})
+
+        if not self.is_valid_body(body, 'upload'):
+            msg = _("Incorrect request body format")
+            raise exc.HTTPBadRequest(explanation=msg)
+
+        context = req.environ['cinder.context']
+        params = body['upload']
+        if not params.get("image_name"):
+            msg = _("No image_name was specified in request.")
+            raise webob.exc.HTTPBadRequest(explanation=msg)
+
+        image_metadata = {
+            "container_format": params.get(
+                "container_format", "bare"),
+            "disk_format": params.get("disk_format", "raw"),
+            "name": params["image_name"],
+            }
+
+        backup = self.backup_api.get(context, id)
+        try:
+            response = self.backup_api.upload(context,
+                                              backup,
+                                              image_metadata)
+        except exception.InvalidBackup as error:
+            raise webob.exc.HTTPBadRequest(explanation=error.msg)
+        except exception.GlanceOperationFailed as error:
+            raise webob.exc.HTTPBadRequest(explanation=error.msg)
+        except Exception as error:
+            raise webob.exc.HTTPBadRequest(explanation=unicode(error))
+
+        retval = self._view_builder.upload_summary(
+            req, dict(response))
+        return retval
+
     @wsgi.response(202)
     @wsgi.serializers(xml=BackupRestoreTemplate)
     @wsgi.deserializers(xml=RestoreDeserializer)
@@ -379,7 +418,7 @@ class Backups(extensions.ExtensionDescriptor):
         res = extensions.ResourceExtension(
             Backups.alias, BackupsController(),
             collection_actions={'detail': 'GET', 'import_record': 'POST'},
-            member_actions={'restore': 'POST', 'export_record': 'GET',
-                            'action': 'POST'})
+            member_actions={'restore': 'POST', 'upload': 'POST',
+                            'export_record': 'GET', 'action': 'POST'})
         resources.append(res)
         return resources
diff --git a/cinder/api/views/backups.py b/cinder/api/views/backups.py
index aafd11ef9..9fe20f9ff 100644
--- a/cinder/api/views/backups.py
+++ b/cinder/api/views/backups.py
@@ -57,6 +57,23 @@ class ViewBuilder(common.ViewBuilder):
             },
         }
 
+    def upload_summary(self, request, upload):
+        """Generic, non-detailed view of a restore."""
+        retval = {
+            'backup_id': upload['id'],
+            'updated_at': upload['updated_at'],
+            'status': upload['status'],
+            'display_description': upload['display_description'],
+            'size': upload['size'],
+            'image_id': upload['image_id'],
+            'container_format': upload['container_format'],
+            'disk_format': upload['disk_format'],
+            'image_name': upload['image_name']
+        }
+        return {
+            'upload': retval
+        }
+
     def detail(self, request, backup):
         """Detailed view of a single backup."""
         return {
diff --git a/cinder/backup/api.py b/cinder/backup/api.py
index 201a4360c..c53249ab0 100644
--- a/cinder/backup/api.py
+++ b/cinder/backup/api.py
@@ -34,6 +34,8 @@ from cinder import utils
 import cinder.volume
 from cinder.volume import utils as volume_utils
 
+from cinder.image import glance
+
 CONF = cfg.CONF
 LOG = logging.getLogger(__name__)
 QUOTAS = quota.QUOTAS
@@ -202,6 +204,58 @@ class API(base.Base):
 
         return backup
 
+    def upload(self, context, backup, metadata):
+        """Create a new image from the specified backup."""
+
+        if backup['status'] not in ['available']:
+            msg = _('Backup status must be available')
+            raise exception.InvalidBackup(reason=msg)
+
+        size = backup['size']
+        if size is None:
+            msg = _('Backup to upload has invalid size')
+            raise exception.InvalidBackup(reason=msg)
+
+        volume_id = backup['volume_id']
+        if volume_id is None:
+            msg = _('Backup to upload has invalid volume_id')
+            raise exception.InvalidBackup(reason=msg)
+
+        try:
+            image_service = glance.get_default_image_service()
+            metadata['version'] = 1
+            metadata['min_disk'] = backup['size']
+            recv_metadata = image_service.create(context,
+                                                 metadata)
+        except Exception:
+            msg = _('Failed to create glance image')
+            raise exception.GlanceOperationFailed(reason=msg)
+
+        # Setting the status here rather than setting at start and unrolling
+        # for each error condition, it should be a very small window
+        backup_host = volume_utils.extract_host(backup['host'], 'host')
+        backup['status'] = 'uploading'
+        self.db.backup_update(context, backup['id'], {'status': 'uploading'})
+
+        self.backup_rpcapi.upload_backup_to_image(context,
+                                                  backup_host,
+                                                  backup,
+                                                  recv_metadata)
+        response = {"id": backup['id'],
+                    "updated_at": backup['updated_at'],
+                    "status": 'uploading',
+                    "display_description": backup['display_description'],
+                    "size": backup['size'],
+                    "image_id": recv_metadata['id'],
+                    "container_format": recv_metadata['container_format'],
+                    "disk_format": recv_metadata['disk_format'],
+                    "image_name": recv_metadata.get('name', None)}
+        LOG.info(_("Uploading backup %(backup_id)s to image %(image_id)s"),
+                 {'backup_id': backup['id'],
+                  'image_id': recv_metadata['id']})
+
+        return response
+
     def restore(self, context, backup_id, volume_id=None):
         """Make the RPC call to restore a volume backup."""
         check_policy(context, 'restore')
diff --git a/cinder/backup/drivers/ceph.py b/cinder/backup/drivers/ceph.py
index a8adbb5a7..a07f181b6 100644
--- a/cinder/backup/drivers/ceph.py
+++ b/cinder/backup/drivers/ceph.py
@@ -61,6 +61,13 @@ from cinder.openstack.common import units
 from cinder import utils
 import cinder.volume.drivers.rbd as rbd_driver
 
+from cinder.openstack.common import fileutils
+from cinder.image import image_utils
+import uuid
+import urllib
+import json
+import tempfile
+
 try:
     import rados
     import rbd
@@ -88,7 +95,10 @@ service_opts = [
                help='RBD stripe count to use when creating a backup image.'),
     cfg.BoolOpt('restore_discard_excess_bytes', default=True,
                 help='If True, always discard excess bytes when restoring '
-                     'volumes i.e. pad with zeroes.')
+                     'volumes i.e. pad with zeroes.'),
+    cfg.StrOpt('image_upload_use_clone',
+               default='True',
+               help='If True, use backend clone for efficiently upload. '),
 ]
 
 CONF = cfg.CONF
@@ -1135,6 +1145,347 @@ class CephBackupDriver(BackupDriver):
             LOG.error(msg)
             raise exception.BackupOperationError(msg)
 
+    def _parse_image_loc(self, location):
+        prefix = 'rbd://'
+        if not location.startswith(prefix):
+            reason = _('Not stored in rbd')
+            raise exception.ImageUnacceptable(image_id=location, reason=reason)
+        pieces = map(urllib.unquote, location[len(prefix):].split('/'))
+        if '' in pieces:
+            reason = _('Blank components')
+            raise exception.ImageUnacceptable(image_id=location, reason=reason)
+        if len(pieces) != 4:
+            reason = _('Not an rbd snapshot')
+            raise exception.ImageUnacceptable(image_id=location, reason=reason)
+        return pieces
+
+    def _get_image_ref(self, volume_id):
+        """Helper method to get image_ref."""
+        json_meta = self.get_metadata(volume_id)
+        metadata = json.loads(json_meta)
+        if 'image_id' in metadata['volume-glance-metadata']:
+            return metadata['volume-glance-metadata']['image_id']
+        else:
+            return None
+
+    def _get_parent_pool(self, image_service, base_image_id, fsid):
+        parent_pool = None
+
+        try:
+            locations = image_service.get_location(self.context, base_image_id)
+        except Exception as e:
+            LOG.debug('Unable to get image %(image_id)s location; error:'
+                      ' %(error)s', {'image_id': base_image_id, 'error': e})
+            locations = ()
+
+        # Find the first location that is in the same RBD cluster
+        for location in locations:
+            if location is None:
+                continue
+            try:
+                parent_fsid, parent_pool, _im, _snap = \
+                    self._parse_image_loc(location)
+                if parent_fsid == fsid:
+                    break
+                else:
+                    parent_pool = None
+            except exception.ImageUnacceptable:
+                continue
+
+        return parent_pool
+
+    def _delete_cloned_glance_image(self, name, ioctx, rbd_image):
+        """Deletes a cloned glance image."""
+        volume_name = strutils.safe_encode(name)
+        snap = strutils.safe_encode('snap')
+
+        try:
+            if rbd_image.is_protected_snap(snap):
+                rbd_image.unprotect_snap(snap)
+            rbd_image.remove_snap(snap)
+        except self.rbd.ImageBusy:
+            raise exception.SnapshotIsBusy(snapshot_name='snap')
+        except self.rbd.ImageNotFound:
+            pass
+
+        LOG.debug("deleting cloned glance image %s" % (volume_name))
+        try:
+            self.rbd.RBD().remove(ioctx, volume_name)
+        except self.rbd.ImageBusy:
+            msg = (_("ImageBusy error raised while deleting rbd "
+                     "volume. This may have been caused by a "
+                     "connection from a client that has crashed and, "
+                     "if so, may be resolved by retrying the delete "
+                     "after 30 seconds has elapsed."))
+            LOG.warn(msg)
+            raise exception.VolumeIsBusy(msg, volume_name=volume_name)
+
+    def clone_backup_to_image(self, backup, image_service,
+                              image_meta, snapshot):
+        """Clone volume and register its location to the image."""
+
+        volume_name = snapshot['volume_name']
+        if snapshot['name']:
+            snap = snapshot['name']
+        else:
+            snap = strutils.safe_encode(uuid.uuid4().hex)
+
+        base_image_id = self._get_image_ref(backup['volume_id'])
+
+        with rbd_driver.RBDVolumeProxy(self, volume_name) as volume:
+            fsid = volume.client.get_fsid()
+
+            # Cinder has zero comprehension of how Glance's image store is
+            # configured, but we can infer what storage pool Glance is using
+            # by looking at the parent image.  If using authx, write access
+            # should be enabled on that pool for the Nova user
+            parent_pool = self._get_parent_pool(image_service,
+                                                base_image_id, fsid)
+            if parent_pool is None:
+                return False
+
+            # librbd requires that snapshots be set to "protected"
+            # in order to clone them
+            if snapshot['name']:
+                if not volume.is_protected_snap(snap):
+                    volume.protect_snap(snap)
+            else:
+                volume.create_snap(snap)
+                volume.protect_snap(snap)
+
+            with rbd_driver.RADOSClient(self,
+                                        str(parent_pool))as dest_client:
+                # clone backup into Glance's storage pool.
+                LOG.debug('cloning %(pool)s/%(img)s@%(snap)s to '
+                          '%(dest_pool)s/%(dest_name)s',
+                          dict(pool=self._ceph_backup_pool,
+                               img=volume_name,
+                               snap=snap,
+                               dest_pool=parent_pool,
+                               dest_name=image_meta['id']))
+                self.rbd.RBD().clone(volume.ioctx,
+                                     volume_name,
+                                     snap,
+                                     dest_client.ioctx,
+                                     str(image_meta['id']),
+                                     features=self.rbd.RBD_FEATURE_LAYERING)
+                try:
+                    dest_volume = self.rbd.Image(dest_client.ioctx,
+                                                 strutils.safe_encode(
+                                                     image_meta['id']),
+                                                 snapshot=None,
+                                                 read_only=False)
+                except Exception:
+                    # if failed to get dest_volume, removing maybe fails
+                    self.rbd.RBD().remove(dest_client.ioctx,
+                                          strutils.safe_encode(
+                                              image_meta['id']))
+                    raise
+
+                try:
+                    # Flatten the image, which detaches it from the
+                    # source snapshot
+                    LOG.debug('flattening %(pool)s/%(img)s' %
+                              dict(pool=parent_pool, img=image_meta['id']))
+                    dest_volume.flatten()
+
+                    # Glance makes a protected snapshot called 'snap' on
+                    # uploaded images and hands it out, so we'll do that too.
+                    # The name of the snapshot doesn't really matter, this
+                    # just uses what the glance-store rbd backend sets
+                    # (which is not configurable)
+                    dest_volume.create_snap(strutils.safe_encode('snap'))
+                    dest_volume.protect_snap(strutils.safe_encode('snap'))
+
+                    # all done with the source snapshot
+                    # backup snap is unprotected originally,so unprotect it
+                    volume.unprotect_snap(snap)
+                    if not snapshot['name']:
+                        volume.remove_snap(snap)
+
+                    # prepare the metadata
+                    metadata = {
+                        'status': 'active',
+                        'name': str(image_meta['name']),
+                    }
+                    metadata['disk_format'] = 'raw'
+                    metadata['container_format'] = 'bare'
+                    metadata['version'] = 1
+                    metadata['location'] = \
+                        str('rbd://%(fsid)s/%(pool)s/%(image)s/snap' %
+                            dict(fsid=fsid, pool=parent_pool,
+                                 image=image_meta['id']))
+                    image_service.update(self.context, str(image_meta['id']),
+                                         metadata, data=None,
+                                         purge_props=False)
+                except Exception:
+                    self._delete_cloned_glance_image(image_meta['id'],
+                                                     dest_client.ioctx,
+                                                     dest_volume)
+                    raise
+                finally:
+                    dest_volume.close()
+
+        return True
+
+    def _image_conversion_dir(self):
+        tmpdir = (CONF.image_conversion_dir or
+                  tempfile.gettempdir())
+
+        # ensure temporary directory exists
+        if not os.path.exists(tmpdir):
+            os.makedirs(tmpdir)
+
+        return tmpdir
+
+    def _get_snapshot(self, backup):
+        """returns: (rbd_name,snap)"""
+        if backup['id'] is None:
+            msg = _("Backup id required")
+            raise exception.InvalidParameterValue(msg)
+
+        with rbd_driver.RADOSClient(self, self._ceph_backup_pool) as client:
+            # diff format
+            base_name = self._get_backup_base_name(backup['volume_id'],
+                                                   diff_format=True)
+            rbd_exists, base_name = self._rbd_image_exists(base_name,
+                                                           backup['volume_id'],
+                                                           client)
+            if rbd_exists:
+                base_rbd = self.rbd.Image(client.ioctx,
+                                          base_name,
+                                          read_only=True)
+                try:
+                    upload_point = \
+                        self._get_backup_snap_name(base_rbd, base_name,
+                                                   backup['id'])
+                finally:
+                    base_rbd.close()
+
+                if upload_point:
+                    return (base_name, upload_point)
+
+            # no snap format
+            rbd_name = self._get_backup_base_name(backup['volume_id'],
+                                                  backup['id'])
+            rbd_exists, rbd_name = self._rbd_image_exists(rbd_name,
+                                                          backup['volume_id'],
+                                                          client)
+            if rbd_exists:
+                return (rbd_name, None)
+
+        raise self.rbd.ImageNotFound(_("backup %s image not found") %
+                                     backup['id'])
+
+    def _copy_backup_to_file(self, snapshot, tmp_path, length):
+        """Copy backup to a local file"""
+        rbd_name = snapshot['volume_name']
+        snap_name = snapshot['name']
+
+        with fileutils.file_open(tmp_path, 'wb') as dest_file:
+            with rbd_driver.RBDVolumeProxy(self, rbd_name,
+                                           snapshot=snap_name,
+                                           read_only=True) as src_rbd:
+                try:
+                    rbd_meta = \
+                        rbd_driver.RBDImageMetadata(src_rbd,
+                                                    self._ceph_backup_pool,
+                                                    self._ceph_backup_user,
+                                                    self._ceph_backup_conf)
+                    rbd_fd = rbd_driver.RBDImageIOWrapper(rbd_meta)
+                    self._transfer_data(rbd_fd, rbd_name, dest_file,
+                                        tmp_path, length)
+
+                    # Be tolerant of IO implementations that do not
+                    # support fileno()
+                    try:
+                        fileno = dest_file.fileno()
+                    except IOError:
+                        LOG.debug("copy backup target I/O object does not "
+                                  "support fileno() - skipping call to "
+                                  "fsync().")
+                    else:
+                        os.fsync(fileno)
+                except exception.BackupOperationError as e:
+                    LOG.error(_('Copy to tempfile %(file)s finished with '
+                                'error - %(error)s.') % {'error': e,
+                                                         'file': tmp_path})
+                    raise
+
+    def copy_backup_to_image(self, backup, image_service, image_meta,
+                             snapshot):
+        """Full copy backup to glance in Ceph object store.
+
+        """
+        LOG.debug('Starting full copy from Ceph backup=%(src)s to glance',
+                  {'src': snapshot['volume_name']})
+
+        tmp_dir = self._image_conversion_dir()
+        tmp_path = os.path.join(tmp_dir,
+                                'backup_upload' + '-' + image_meta['id'])
+
+        if tmp_dir and not os.path.exists(tmp_dir):
+            os.makedirs(tmp_dir)
+
+        length = int(backup['size']) * units.Gi
+
+        with fileutils.remove_path_on_error(tmp_path):
+            self._copy_backup_to_file(snapshot, tmp_path, length)
+            image_utils.upload(self.context, image_service,
+                               image_meta, tmp_path)
+        os.unlink(tmp_path)
+
+    def upload_backup_to_image(self, backup, image_service, image_meta):
+        """Upload backup to glance in Ceph object store.
+
+        """
+        LOG.debug('Starting upload from Ceph backup=%(src)s to glance',
+                  {'src': backup['id']})
+
+        try:
+            backup_volume_name, snap = self._get_snapshot(backup)
+        except Exception:
+            LOG.debug("Failed to get rbd name of  backup %s.",
+                      backup['id'])
+            raise
+
+        snapshot = {}
+        snapshot['volume_name'] = strutils.safe_encode(backup_volume_name)
+        if snap is not None:
+            snapshot['name'] = strutils.safe_encode(snap)
+        else:
+            snapshot['name'] = None
+
+        do_clone_upload = False
+        if (image_meta['disk_format'] == 'raw' and
+                image_meta['container_format'] == 'bare'):
+            if self._supports_layering and CONF.image_upload_use_clone:
+                try:
+                    do_clone_upload = \
+                        self.clone_backup_to_image(backup,
+                                                   image_service,
+                                                   image_meta,
+                                                   snapshot)
+                except Exception:
+                    LOG.debug("Cloned backup %(backup_id)s to "
+                              "image-id: %(image_id)s failed.",
+                              {'backup_id': backup['id'],
+                               'image_id': image_meta['id']})
+
+            if do_clone_upload:
+                LOG.debug("Cloned backup %(backup_id)s to "
+                          "image-id: %(image_id)s finished.",
+                          {'backup_id': backup['id'],
+                           'image_id': image_meta['id']})
+        # do full upload
+        if not do_clone_upload:
+            self.copy_backup_to_image(backup, image_service, image_meta,
+                                      snapshot)
+            LOG.debug("Full Upload backup %(backup_id)s to "
+                      "image-id: %(image_id)s finished.",
+                      {'backup_id': backup['id'],
+                       'image_id': image_meta['id']})
+
     def restore(self, backup, volume_id, volume_file):
         """Restore volume from backup in Ceph object store.
 
diff --git a/cinder/backup/manager.py b/cinder/backup/manager.py
index b7590815c..d337e56eb 100644
--- a/cinder/backup/manager.py
+++ b/cinder/backup/manager.py
@@ -50,6 +50,8 @@ from cinder import rpc
 from cinder import utils
 from cinder.volume import utils as volume_utils
 
+from cinder.image import glance
+
 LOG = logging.getLogger(__name__)
 
 backup_manager_opts = [
@@ -405,6 +407,90 @@ class BackupManager(manager.SchedulerDependentManager):
                                                    self.az})
         LOG.info(_('Create backup finished. backup: %s.'), backup_id)
 
+    def _delete_image(self, context, image_id, image_service):
+        """Deletes an image stuck in queued or saving state."""
+        try:
+            image_meta = image_service.show(context, image_id)
+            image_status = image_meta.get('status')
+            if image_status == 'queued' or image_status == 'saving':
+                LOG.warn("Deleting image %(image_id)s in %(image_status)s "
+                         "state.",
+                         {'image_id': image_id,
+                          'image_status': image_status})
+            image_service.delete(context, image_id)
+        except Exception:
+            LOG.warn(_("Error occurred while deleting image %s."),
+                     image_id, exc_info=True)
+
+    def upload_backup_to_image(self, context, backup, image_meta):
+        """Uploads the specified backup to Glance.
+
+        image_meta is a dictionary containing the following keys:
+        'id', 'container_format', 'disk_format'
+
+        """
+        LOG.info(_('Upload backup started, backup: %(backup_id)s '
+                   'image_id: %(image_id)s.'),
+                 {'backup_id': backup['id'], 'image_id': image_meta['id']})
+        self.db.backup_update(context, backup['id'], {'host': self.host})
+
+        payload = {'backup_id': backup['id'], 'image_id': image_meta['id']}
+
+        expected_status = 'uploading'
+        actual_status = backup['status']
+        if actual_status != expected_status:
+            err = (_('Upload backup aborted: expected backup status '
+                     '%(expected_status)s but got %(actual_status)s.') %
+                   {'expected_status': expected_status,
+                    'actual_status': actual_status})
+            self.db.backup_update(context, backup['id'], {'status': 'error',
+                                  'fail_reason': err})
+            raise exception.InvalidBackup(reason=err)
+
+        backup_service = self._map_service_to_driver(backup['service'])
+        configured_service = self.driver_name
+        if backup_service != configured_service:
+            err = _('Upload backup aborted, the backup service currently'
+                    ' configured [%(configured_service)s] is not the'
+                    ' backup service that was used to create this'
+                    ' backup [%(backup_service)s].') % {
+                'configured_service': configured_service,
+                'backup_service': backup_service,
+            }
+            self.db.backup_update(context, backup['id'],
+                                  {'status': 'available'})
+            raise exception.InvalidBackup(reason=err)
+
+        try:
+
+            utils.require_driver_initialized(self.driver)
+            image_service, image_id = \
+                glance.get_remote_image_service(context, image_meta['id'])
+
+            backup_service = self.service.get_backup_driver(context)
+
+            backup_service.upload_backup_to_image(backup,
+                                                  image_service,
+                                                  image_meta)
+        except Exception as error:
+            LOG.error(_("Error occurred while uploading backup %(backup_id)s "
+                        "to image %(image_id)s."),
+                      {'backup_id': backup['id'],
+                       'image_id': image_meta['id']})
+            if image_service is not None:
+                # Deletes the image if it is in queued or saving state
+                self._delete_image(context, image_meta['id'], image_service)
+
+            with excutils.save_and_reraise_exception():
+                payload['message'] = unicode(error)
+        finally:
+            self.db.backup_update(context, backup['id'],
+                                  {'status': 'available'})
+
+        LOG.info(_('Upload backup finished, backup %(backup_id)s uploaded'
+                   ' to glance %(image_id)s.') %
+                 {'backup_id': backup['id'], 'image_id': image_meta['id']})
+
     def restore_backup(self, context, backup_id, volume_id):
         """Restore volume backups from configured backup service."""
         LOG.info(_('Restore backup started, backup: %(backup_id)s '
diff --git a/cinder/backup/rpcapi.py b/cinder/backup/rpcapi.py
index 1d59c2e33..f2d7dd52a 100644
--- a/cinder/backup/rpcapi.py
+++ b/cinder/backup/rpcapi.py
@@ -57,6 +57,12 @@ class BackupAPI(object):
         cctxt.cast(ctxt, 'restore_backup', backup_id=backup_id,
                    volume_id=volume_id)
 
+    def upload_backup_to_image(self, ctxt, host, backup, image_meta):
+        LOG.debug("upload_backup_to_image in rpcapi backup_id %s", backup['id'])
+        cctxt = self.client.prepare(server=host)
+        cctxt.cast(ctxt, 'upload_backup_to_image', backup=backup,
+                   image_meta=image_meta)
+
     def delete_backup(self, ctxt, host, backup_id):
         LOG.debug("delete_backup  rpcapi backup_id %s", backup_id)
         cctxt = self.client.prepare(server=host)
diff --git a/cinder/exception.py b/cinder/exception.py
index fc747ce6f..420190c50 100644
--- a/cinder/exception.py
+++ b/cinder/exception.py
@@ -869,3 +869,7 @@ class HBSDNotFound(NotFound):
 # Datera driver
 class DateraAPIException(VolumeBackendAPIException):
     message = _("Bad response from Datera API")
+
+
+class GlanceOperationFailed(CinderException):
+    message = _("An error has occurred during glance operation: %(reason)s")
diff --git a/cinder/image/image_utils.py b/cinder/image/image_utils.py
index 361e36fc1..4f4ccea16 100644
--- a/cinder/image/image_utils.py
+++ b/cinder/image/image_utils.py
@@ -290,16 +290,22 @@ def fetch_to_volume_format(context, image_service,
 
 def upload_volume(context, image_service, image_meta, volume_path,
                   volume_format='raw'):
+    upload(context, image_service, image_meta, volume_path,
+           volume_format)
+
+
+def upload(context, image_service, image_meta, src_path,
+           volume_format='raw'):
     image_id = image_meta['id']
     if (image_meta['disk_format'] == volume_format):
         LOG.debug("%s was %s, no need to convert to %s" %
                   (image_id, volume_format, image_meta['disk_format']))
-        if os.name == 'nt' or os.access(volume_path, os.R_OK):
-            with fileutils.file_open(volume_path, 'rb') as image_file:
+        if os.name == 'nt' or os.access(src_path, os.R_OK):
+            with fileutils.file_open(src_path, 'rb') as image_file:
                 image_service.update(context, image_id, {}, image_file)
         else:
-            with utils.temporary_chown(volume_path):
-                with fileutils.file_open(volume_path) as image_file:
+            with utils.temporary_chown(src_path):
+                with fileutils.file_open(src_path) as image_file:
                     image_service.update(context, image_id, {}, image_file)
         return
 
@@ -312,7 +318,7 @@ def upload_volume(context, image_service, image_meta, volume_path,
     with fileutils.remove_path_on_error(tmp):
         LOG.debug("%s was %s, converting to %s" %
                   (image_id, volume_format, image_meta['disk_format']))
-        convert_image(volume_path, tmp, image_meta['disk_format'],
+        convert_image(src_path, tmp, image_meta['disk_format'],
                       bps_limit=CONF.volume_copy_bps_limit)
 
         data = qemu_img_info(tmp)
-- 
2.15.0

